{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp vision.core\n",
    "#default_cls_lvl 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from local.imports import *\n",
    "from local.test import *\n",
    "from local.core import *\n",
    "from local.data.pipeline import *\n",
    "from local.data.core import *\n",
    "from local.data.external import *\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "_all_ = ['Image']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "torch.cuda.set_device(int(os.environ.get('DEFAULT_GPU') or 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Core vision\n",
    "> Basic image opening/processing functionality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/sgugger/git/fastai_docs/dev/data/mnist_tiny/train/3/8055.png')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = untar_data(URLs.MNIST_TINY)\n",
    "fns = get_image_files(path)\n",
    "fn = fns[0]; fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class PILImage():\n",
    "    kwargs = dict(cmap='viridis')\n",
    "    @staticmethod\n",
    "    def show(o, ctx=None, **kwargs): return show_image(o, ctx=ctx, **{**PILImage.kwargs, **kwargs})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Imagify(Transform):\n",
    "    \"Open an `Image` from path `fn`\"\n",
    "    def __init__(self, func=Image.open):  self.func = func\n",
    "    def encodes(self, fn)->PILImage: return self.func(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA4ElEQVR4nMWRsQ4BQRRFr41ESaKgYgqJdnUKke2U+AF8gU7hA3Si0GkU+v0ExNaiobSRiEpEFBLFzcsqlhA7qxO3mnln3rv3ZYD/Ke14I7vV0kOLQpLziooGoVoKSQrZ1rQmpycfXl0rEcQVm/5sKeutS+OViOeGpR6Qcm36l49spp0BEMtq2oqTI0nKLh5ktcsjUDfIlIh4IrLQZVEk5batp0Jh/71ivI6HIYC90vUBMHsULpOvgr+ncjtnABHDQMGpbjV2j1/hRuf5VP4DHnKzkBwAgHTjOXbd+Pbu57oDyUZ5YLf9a8QAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=L size=28x28 at 0x7FBC27544278>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timg = Imagify()\n",
    "img = timg(fn)\n",
    "test_eq(img.size, (28,28))\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Mask(PILImage):\n",
    "    kwargs = dict(cmap='tab20', alpha=0.5)\n",
    "    @staticmethod\n",
    "    def show(o, ctx=None, **kwargs): return show_image(o, ctx=ctx, **{**Mask.kwargs, **kwargs})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Maskify(Transform):\n",
    "    \"Open an `Image` from path `fn`\"\n",
    "    def __init__(self, func=Image.open): self.func = func\n",
    "    def encodes(self, fn)->Mask: return self.func(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmask = Maskify(func=lambda fn: Image.fromarray((array(Image.open(fn)) >= 127).astype(np.uint8)))\n",
    "mask = tmask(fn)\n",
    "test_eq(mask.size, (28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class TensorPoint():\n",
    "    kwargs = dict(s=10, marker='.', c='r')\n",
    "    @staticmethod\n",
    "    def show(o, ctx=None, **kwargs): \n",
    "        if 'figsize' in kwargs: del kwargs['figsize']\n",
    "        ctx.scatter(o[:, 1], o[:, 0], **{**TensorPoint.kwargs, **kwargs})\n",
    "        return ctx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class Pointify(Transform):\n",
    "    def encodes(self, t)->TensorPoint: return tensor(t).view(-1, 2).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pnts = np.array([[0,0], [14,0], [28,0], [0,28], [14,28], [28,28]])\n",
    "tpnts = Pointify()(pnts)\n",
    "test_eq(tpnts.shape, [6,2])\n",
    "test_eq(tpnts.dtype, torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "from fastai.vision.data import get_annotations\n",
    "from matplotlib import patches, patheffects\n",
    "\n",
    "def _draw_outline(o, lw):\n",
    "    o.set_path_effects([patheffects.Stroke(linewidth=lw, foreground='black'), patheffects.Normal()])\n",
    "\n",
    "def _draw_rect(ax, b, color='white', text=None, text_size=14, hw=True, rev=False):\n",
    "    lx,ly,w,h = b\n",
    "    if rev: lx,ly,w,h = ly,lx,h,w\n",
    "    if not hw: w,h = w-lx,h-ly\n",
    "    patch = ax.add_patch(patches.Rectangle((lx,ly), w, h, fill=False, edgecolor=color, lw=2))\n",
    "    _draw_outline(patch, 4)\n",
    "    if text is not None:\n",
    "        patch = ax.text(lx,ly, text, verticalalignment='top', color=color, fontsize=text_size, weight='bold')\n",
    "        _draw_outline(patch,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class TensorBBox(TensorPoint):\n",
    "    @staticmethod\n",
    "    def show(x, ctx=None, **kwargs):\n",
    "        bbox,label = x\n",
    "        for b,l in zip(bbox, label): \n",
    "            if l != '#bg': _draw_rect(ctx, b, hw=False, rev=True, text=l)\n",
    "        return ctx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class BBoxify(Transform):\n",
    "    def encodes(self, x)->TensorBBox: return (tensor(x[0]).view(-1, 4).float(),x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bboxes = (np.array([[0,0,7,7], [10,14,27, 27]]), ['tl', 'br'])\n",
    "tbbs = BBoxify()(bboxes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ImageConverter(Transform):\n",
    "    \"Convert `img` to `mode`\"\n",
    "    def __init__(self, mode='RGB', mask_mode='L'): self.modes = (mode,mask_mode)\n",
    "    def encodes(self, o:PILImage): return o.convert(self.modes[0])\n",
    "    def encodes(self, o:Mask):     return o.convert(self.modes[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = ImageConverter('RGB')\n",
    "f.accept_types(PILImage)\n",
    "test_eq(f(img).mode, 'RGB')\n",
    "f.accept_types(Mask)\n",
    "test_eq(f(mask).mode, 'L')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def image_resize(img, size, resample=Image.BILINEAR):\n",
    "    \"Resize image to `size` using `resample\"\n",
    "    return img.resize(size, resample=resample)\n",
    "image_resize.order=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ImageResizer(Transform):\n",
    "    \"Resize image to `size` using `resample\"\n",
    "    def __init__(self, size, resample=Image.BILINEAR):\n",
    "        if not is_listy(size): size=(size,size)\n",
    "        self.size,self.resample = size,resample\n",
    "\n",
    "    def encodes(self, o:PILImage): return image_resize(o, size=self.size, resample=self.resample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = ImageResizer(14)\n",
    "f.accept_types(PILImage)\n",
    "test_eq(f(img).size, (14,14))\n",
    "f.accept_types(Mask)\n",
    "test_eq(f(mask).size, (14,14))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def image2byte(img):\n",
    "    \"Transform image to byte tensor in `c*h*w` dim order.\"\n",
    "    res = torch.ByteTensor(torch.ByteStorage.from_buffer(img.tobytes()))\n",
    "    w,h = img.size\n",
    "    return res.view(h,w,-1).permute(2,0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ImageToByteTensor(Transform):\n",
    "    \"Transform image to byte tensor in `c*h*w` dim order.\"\n",
    "    order = 15\n",
    "    def encodes(self, o:PILImage)->TensorImage: return image2byte(o)\n",
    "    def encodes(self, o:Mask)    ->TensorMask:  return image2byte(o)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfm = ImageToByteTensor()\n",
    "tfm.accept_types(PILImage)\n",
    "test_eq(tfm(img).shape, (1,28,28))\n",
    "test_eq(tfm.return_type(), TensorImage)\n",
    "tfm.accept_types(Mask)\n",
    "test_eq(tfm(mask).shape, (28,28))\n",
    "test_eq(tfm.return_type(), TensorMask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's confirm we can pipeline this with `Imagify`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFkAAABYCAYAAACeV1sKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAA4BJREFUeJzt2r8rfXEcx/EnfcuPQSImoqQUg8wMfpSJUgalzP4BkfKjLGYmm0FRDBgMRmWQRQx+pEwWSeoqSl3f4dvn3u91neN+D96fe+739VjPOZ1Pr17efc7nKnp7e0N+VrHvBfwPFLIBhWxAIRtQyAYUsgGFbEAhG/hl/L5C/vIpCrqgJhtQyAYUsgGFbEAhG1DIBhSyAet9ciRPT08AjI6OArC7uwvA9PQ0AHd3dwCMjIyknunt7bVcYig12UCR8c9PkV52eXkJQFtbGwDJZBKA4uLgjgwODgIwPz8PQH19PQAVFRWfPhuRvvh8ikWTHx8fARgaGgLg4OAACG9jUNvX19cBGB4ejrKUMGqyT7FosvP8/AzA2NgYkG70w8ND1r1BTS4tLQWgrq4OgO3tbQAaGhoyrkegJvsUqya/d3Z2BsDS0hIAq6urqWu57ED+vu/i4gKA5ubmqMtRk32KdZPDXF9fA7CysgLA0dERAIeHhxn3uSa3tLQAcH5+HvWVarJPBdtkx517LC8vAzA7O5tx3TW5vLwcgJ2dHQB6enr+9VVqsk+xOIWL4vb2FoC+vj4gPaODvLy8AHB1dQVEanIgNdlAQc3km5sb4M++eWNjA4D7+/vQZ9xMbmpqAuD09BSI9OWnmexTQczk4+NjAPr7+wFIJBI5f/E5U1NTwJfOLgLFely4I9Dq6uqsa5+FPDAwAKQPiL6BxoVPBTEuwkZCSUkJAI2NjUD6EKm1tfWnl5WiJhsoiCaHmZubA2ByctLbGtRkA7Fusvt5f2FhAYCZmZmse9xHhtuJVFZWGq0uTU02EOt9suMOgzY3NwGYmJjI2id3dnYCsLe3B0BZWdl3L0P7ZJ/ycia//5JbW1sDoLa2NvQ591eZTCZTTXbcvw90dXUBsL+/D0BVVdU3rTqYmmwgL2eya3JNTc2H13M5/Pnsnvb2diB9uPQNNJN9ysuZbOHk5MTsXWqygbycyW6eJhIJAMbHxwHY2trKuP6Vmey8vr7msqRcaCb7lJdNfs/9g4rbCbif+aM0uaOjA4DFxUUAuru7oyzpI2qyT7FockyoyT4pZAMK2YBCNqCQDShkAwrZgPUpXOBespCpyQYUsgGFbEAhG1DIBhSyAYVsQCEbUMgGFLIBhWxAIRtQyAYUsgGFbEAhG1DIBhSyAYVsQCEbUMgGFLIBhWzgN2DhGcF3EMK+AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pipe_img = Pipeline([Imagify(), ImageToByteTensor()])\n",
    "img = pipe_img(fn)\n",
    "test_eq(img.shape, (1,28,28))\n",
    "PILImage.kwargs['cmap'] = 'Greys'\n",
    "pipe_img.show(img, figsize=(1,1));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFkAAABYCAYAAACeV1sKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAAZ5JREFUeJzt3MFtwkAYBWETpZC0QB0pgyZys3xLE5SROmiBTpyTpciCdZB3Z3d/z3dFwmj0ZBljcZrneVBZb7U/wBEYGWBkgJEBRgYYGWBkgJEB7+TBPr5+RvJ4pPv35/TsNZcMMDLAyAAjA4wMMDLAyAD0Onmv8XJOvj5db9AneY1LBnS15C2Plt7Cul0yINSSH1mvu8ayXTKgqyUvK9y6ykipsWyXDOhqyYv1+nIsu+SiXTKgyyWvpVb435WXXLRLBoSPPF1v1b/1hY/cghDn5JQ9Vx65uGRAyCW3sN6/XDIg1JL3LLjkFUiIyK3GXXi6AIRY8iu8aR/UYZZc86u1SwaEX3Ltm0PD4JIRIZac+oHVRwIOounI4+Wc/WZPiffc0nTkKLo4J5dYHvEowMIlA4wMMDKg6cgt/JyfQ9ORo+ji6iLnA4bP3rMklwzoYslrvZ2nXTLAyAAjA4wMMDLAyAAjA07+f3J5LhlgZICRAUYGGBlgZICRAUYGGBlgZICRAUYGGBlgZICRAUYGGBlgZICRAUYGGBlgZICRAb/MzFCn8+a0+gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pipe_mask = Pipeline([tmask, ImageToByteTensor()])\n",
    "mask = pipe_mask(fn)\n",
    "test_eq(mask.shape, (28,28))\n",
    "pipe_mask.show(mask, figsize=(1,1));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFkAAABYCAYAAACeV1sKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAA9NJREFUeJztnEtPG1cYhh8TBwNG2JgAIlVITNK6stoqm0hRUxJKG5ZZtesuu81P6V/ovrtKlUorVs1lkahIEOoQtWCII6TEgBxxm4DcxfgQcbGhMH7xuN+zseWZM/549ejo3EykXC5j1JeWsy7g/4CFLMBCFmAhC7CQBVjIAixkARaygKjyy374fbZpZz73v/4oUu2amSzAQhZgIQuwkAVYyAIsZAEWsgDpOPmkeJ4HwJt/HgLw/HkOgOHh2wCsra0BUHx3YbfN0FBaWWJNzGQBoTD5bektAC9ezAIQifiTqwcP/qjapmP7YwBaEv5rV6ILgFgstucZCsxkAaEwOd4ZB2Bw8DIA+fz8kW1yub8AiERyez7vvfoFANlsNsAKa2MmCwiFyW1tbQBcyn4FQEfHI+C90RsbG8d+1kr+MQBTKzMAXMx8CUAimQAgGg0+EjNZQChMdkTP++X2fzgMQKQrA0DMywMwOfnnkc/Y3t4GYHl5GYDiw58A+OzWtwCkelIBVuxjJgsIlcn76evvc+8AuHPpxu41Z2p8pwBAofASgIWFhT3PcMfUCrkJAFK3vgm8TjNZQKhNrkUq5fetntcJwLX2dgAWFxcPvb9UKgEwNzcHQDod3NqHmSygaU126x3zU78C7/voarhRR7FYBMzk0NFUJq+urAL+uDk3PQXA+vr6sdp2J7sByF6/HnhdZrKApjD5VeEVAAvTvwGw5W3tjn+Pu26803kNqM/aRahD3tzcBGD26c8Hrh31W5hMxp+SD2RGAq9rP9ZdCAi1yY5aXUL0nP8nJpNJALqv3ATgQm9f1TZBYyYLaAqTa3FnZASAnfjVM6vBTBYQapPd9v7o6CgAExMTB+6Zym8BMDTkj0TcVpYSM1lAqE12o4rVnX4AxsbGABgfH9+95/Xf/gGY9nf+EqfbjHVbWQrMZAENabKbyT0e/xGAnvTnAMTjnTXb9Vz0zS6XywdmfO74gOf9AsDgJ3cBaK8s5tcTM1lAQ5rscH3u8rx/mMUtu1db/Fl8xoHP99+ztLRUeecvJmVu3Auw4sMxkwU0tMn1xBmdEXyXmSygIU12M7mbd78DoFR4AsDMzLMzq+k0mMkCGtJkNyKItflGJyrHrwZbPgAgX9nmPwkDAwMAnO/59DQl/ifMZAENafJ+WltbAUinr1Revz+zWk6CmSzAQhZgIQuwkAVYyAIsZAEWsoCI/f/k+mMmC7CQBVjIAixkARayAAtZgIUswEIWYCELsJAFWMgCLGQBFrIAC1mAhSzAQhZgIQuwkAVYyAIsZAEWsgALWYCFLOBfXenO+ykFja4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = pipe_img.show(img, figsize=(1,1));\n",
    "pipe_mask.show(mask, ctx=ax);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class PointScaler(Transform):\n",
    "    def __init__(self, do_scale=True, y_first=False): self.do_scale,self.y_first = do_scale,y_first\n",
    "    \n",
    "    def encodes(self, x, y:TensorPoint):\n",
    "        sz = x.shape[-2:] if isinstance(x, Tensor) else [x.size[1],x.size[0]]\n",
    "        if self.do_scale: y = y * 2/tensor(sz).float() - 1\n",
    "        if not self.y_first: y = y.flip(1)\n",
    "        return (x,y)\n",
    "    \n",
    "    def decodes(self, x, y:TensorPoint):\n",
    "        y = y.flip(1)\n",
    "        sz = x.shape[-2:] if isinstance(x, Tensor) else [x.size[1],x.size[0]]\n",
    "        y = (y+1) * tensor([x.shape[-2:]]).float()/2\n",
    "        return (x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _lbl(x): return pnts\n",
    "tds = TfmdDS([fn], [[Imagify(), ImageToByteTensor()], [_lbl,Pointify()]], tuple_tfms=PointScaler())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = tds[0]\n",
    "#Scaling and flipping properly done\n",
    "test_eq(y, tensor([[-1., -1.], [-1.,  0.], [-1.,  1.], [ 1., -1.], [ 1.,  0.], [ 1.,  1.]]))\n",
    "a,b = tds.decode((x,y))\n",
    "test_eq(b, tensor(pnts).float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAI4AAACOCAYAAADn/TAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAABQ5JREFUeJzt3c0rfF8Ax/Fz9S1PJREroqQUZbJm4aGsKGWhlLV/QKQ8xMaalZ2FolhgYWGpLGQzw8JDyspGkqIoZX4Lv+7vnvtr5jvzmZkzD96vjXM633vvKZ/vvefcB8eLx+MGSFdZvjuA4kRwICE4kBAcSAgOJAQHEoIDCcGB5I/j43G3sTB56W7g/oxzdGRMJPLzE4XB80aM50WN542kvInjRw5xE4kYE4sZ091tTDTq8thIxPNixphuY0zMxOORVDZxf8ZZWfkJzcqK80MjoQVjTOzfnylxf8ZBISqCMQ5KAsGBhOBAQnAgITiQEBxICA4kBAcSggOJ66fjOff+/m7VJycnrfpR4OHq/Py81fb09GTVJyYmEh5ncHBQ7WJJ4IwDCcGBpOQect7e3lr1rq4uq/79/e2Xy8r0/zejo6NWfXl52S83NzdbbTU1NVY9k+PmCA854QbBgYTgQFJyY5zX11erPjY2ZtVPT0/9ciZjjeBY6W/72tnZserj4+PycXOEMQ7cIDiQlNylKuzj48OqT01N+eXgZcsYY15eXlLebzqXqoqKCqve1NTklw8ODqy2lpaWhNvlEJcquEFwICE4kJT8GCeZq6srq76+vm7Vt7a2Em6bzhgnmfB+bm5u/HJ7e7u0TwFjHLhBcCAhOJD86jFOJu7v76365uamXz4/P7fazs7OEu4nPMbp6Ojwy9fX15l0MR2MceAGwYGES1WWBF+S39jYsNoWFxcTbhe+VFVVVfnlw8NDq21gYCCTLibDpQpuEBxICA4kJfdBniuPj49WfWhoyC+Hp+rp+Pz89Mt3d3dWWw7HOGnjjAMJwYGE4EDCfZwkHh4e/HL4lYvd3V2r/vz8LB0jfB+nra3NL19eXlptOXyVlPs4cIPgQMJ0PODi4sKqDw8P++W3tzerLVtvAIbNzc35ZYdfOaSNMw4kBAcSggPJr56Oh/9AQX19fcrbZjLGGRn5bz2x8JeceVIE03FWyCs8wgp57oOzuPizQl6Sl5vg3Kr5WSFvNdUNWCEPxrBCXnrCY5yGhoaUtw2PccrLy/1ya2ur1Rb+IrSzs9MvV1dXp3zMHCqCMQ5KAsGBhEcOWbK0tOSXZ2dn89gTNzjjQEJwICE4kPzqMU54jYXVVfv+18JCyrc1rDf3wtP82tpaoXeFjTMOJAQHEoIDya9+5BAW/jpzb2/PL8/MzFhtyV6r6O3ttdqOj4+temVlZUb9zAEeOcANggNJUU7Hk725t729bbU1NjbKxwlexsOXpnA9KLxGRF9fn1U/OTnxy3V1dXL/8okzDiQEBxKCA0lRTsez9eaeq6UVwyKRiF8Ofz2aJ0zH4QbBgaQop+PFLhqN5rsLGeOMAwnBgYTgQFKU0/HwVDj4R4+mp6ettv39/YTb5ms6HvT19SX3IYuYjsMNggMJwYGkKMc4yQTXjTLm/7f0g2suuBrj9PT0WPW1tTW/3N/fL/chixjjwA2CA0nJXaog4VIFNwgOJAQHEoIDCcGBhOBAQnAgITiQEBxICA4kBAcSggMJwYGE4EDi+kvOtB/fozC5P+MIy/ghx4TfiesXuYzxvKj5WcYvZuLxyN/+ORwQfif5GOOkvYwfcq7gl1ZEiWBWBQnBgYTgQEJwICE4kBAcSAgOJAQHEoIDCcGBhOBAQnAgITiQEBxICA4kBAcSggMJwYGE4EBCcCAhOJAQHEgIDiQEBxKCAwnBgYTgQPIPdAJfEiiEVzsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 144x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "tds.show_at(0, figsize=(2,2));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _lbl(x): return pnts\n",
    "tds = TfmdDS([fn], [[Imagify()], [_lbl,Pointify()]], tuple_tfms=[PointScaler(), ImageToByteTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = tds[0]\n",
    "#Scaling and flipping properly done\n",
    "test_eq(y, tensor([[-1., -1.], [-1.,  0.], [-1.,  1.], [ 1., -1.], [ 1.,  0.], [ 1.,  1.]]))\n",
    "a,b = tds.decode((x,y))\n",
    "test_eq(b, tensor(pnts).float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAI4AAACOCAYAAADn/TAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAABQ5JREFUeJzt3c0rfF8Ax/Fz9S1PJREroqQUZbJm4aGsKGWhlLV/QKQ8xMaalZ2FolhgYWGpLGQzw8JDyspGkqIoZX4Lv+7vnvtr5jvzmZkzD96vjXM633vvKZ/vvefcB8eLx+MGSFdZvjuA4kRwICE4kBAcSAgOJAQHEoIDCcGB5I/j43G3sTB56W7g/oxzdGRMJPLzE4XB80aM50WN542kvInjRw5xE4kYE4sZ091tTDTq8thIxPNixphuY0zMxOORVDZxf8ZZWfkJzcqK80MjoQVjTOzfnylxf8ZBISqCMQ5KAsGBhOBAQnAgITiQEBxICA4kBAcSggOJ66fjOff+/m7VJycnrfpR4OHq/Py81fb09GTVJyYmEh5ncHBQ7WJJ4IwDCcGBpOQect7e3lr1rq4uq/79/e2Xy8r0/zejo6NWfXl52S83NzdbbTU1NVY9k+PmCA854QbBgYTgQFJyY5zX11erPjY2ZtVPT0/9ciZjjeBY6W/72tnZserj4+PycXOEMQ7cIDiQlNylKuzj48OqT01N+eXgZcsYY15eXlLebzqXqoqKCqve1NTklw8ODqy2lpaWhNvlEJcquEFwICE4kJT8GCeZq6srq76+vm7Vt7a2Em6bzhgnmfB+bm5u/HJ7e7u0TwFjHLhBcCAhOJD86jFOJu7v76365uamXz4/P7fazs7OEu4nPMbp6Ojwy9fX15l0MR2MceAGwYGES1WWBF+S39jYsNoWFxcTbhe+VFVVVfnlw8NDq21gYCCTLibDpQpuEBxICA4kJfdBniuPj49WfWhoyC+Hp+rp+Pz89Mt3d3dWWw7HOGnjjAMJwYGE4EDCfZwkHh4e/HL4lYvd3V2r/vz8LB0jfB+nra3NL19eXlptOXyVlPs4cIPgQMJ0PODi4sKqDw8P++W3tzerLVtvAIbNzc35ZYdfOaSNMw4kBAcSggPJr56Oh/9AQX19fcrbZjLGGRn5bz2x8JeceVIE03FWyCs8wgp57oOzuPizQl6Sl5vg3Kr5WSFvNdUNWCEPxrBCXnrCY5yGhoaUtw2PccrLy/1ya2ur1Rb+IrSzs9MvV1dXp3zMHCqCMQ5KAsGBhEcOWbK0tOSXZ2dn89gTNzjjQEJwICE4kPzqMU54jYXVVfv+18JCyrc1rDf3wtP82tpaoXeFjTMOJAQHEoIDya9+5BAW/jpzb2/PL8/MzFhtyV6r6O3ttdqOj4+temVlZUb9zAEeOcANggNJUU7Hk725t729bbU1NjbKxwlexsOXpnA9KLxGRF9fn1U/OTnxy3V1dXL/8okzDiQEBxKCA0lRTsez9eaeq6UVwyKRiF8Ofz2aJ0zH4QbBgaQop+PFLhqN5rsLGeOMAwnBgYTgQFKU0/HwVDj4R4+mp6ettv39/YTb5ms6HvT19SX3IYuYjsMNggMJwYGkKMc4yQTXjTLm/7f0g2suuBrj9PT0WPW1tTW/3N/fL/chixjjwA2CA0nJXaog4VIFNwgOJAQHEoIDCcGBhOBAQnAgITiQEBxICA4kBAcSggMJwYGE4EDi+kvOtB/fozC5P+MIy/ghx4TfiesXuYzxvKj5WcYvZuLxyN/+ORwQfif5GOOkvYwfcq7gl1ZEiWBWBQnBgYTgQEJwICE4kBAcSAgOJAQHEoIDCcGBhOBAQnAgITiQEBxICA4kBAcSggMJwYGE4EBCcCAhOJAQHEgIDiQEBxKCAwnBgYTgQPIPdAJfEiiEVzsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 144x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "tds.show_at(0, figsize=(2,2));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class BBoxScaler(Transform):\n",
    "    def __init__(self): \n",
    "        self.scale = PointScaler()\n",
    "        self.scale.accept_types([TensorImage, TensorPoint])\n",
    "        \n",
    "    def encodes(self, x, y:TensorBBox): \n",
    "        return (x,(self.scale((x,y[0].view(-1,2)))[1].view(-1,4),y[1]))\n",
    "    \n",
    "    def decodes(self, x, y:TensorBBox):    \n",
    "        _,bbox = self.scale.decode((x,y[0].view(-1,2)))\n",
    "        return (x, (bbox.view(-1,4), y[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fails\n",
    "#class BBoxScaler(PointScaler):\n",
    "#    def encodes(self, x:TensorImage, y:TensorBBox): \n",
    "#        return (x,(super().__call__((x,y[0].view(-1,2)))[1].view(-1,4),y[1]))\n",
    "#    \n",
    "#    def decodes(self, x:TensorImage, y:TensorBBox):    \n",
    "#        _,bbox = super().decode((x,y[0].view(-1,2)))\n",
    "#        return (x, (bbox.view(-1,4), y[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class BBoxCategorize(Transform):\n",
    "    \"Reversible transform of category string to `vocab` id\"\n",
    "    order,state_args=1,'vocab'\n",
    "    def __init__(self, vocab=None, subset_idx=None):\n",
    "        self.vocab,self.subset_idx = vocab,subset_idx\n",
    "        self.o2i = None if vocab is None else {v:k for k,v in enumerate(vocab)}\n",
    "        \n",
    "    def setup(self, dsrc):\n",
    "        if not dsrc: return\n",
    "        dsrc = dsrc.train if self.subset_idx is None else dsrc.subset(self.subset_idx)\n",
    "        vals = set()\n",
    "        for b,c in dsrc: vals = vals.union(set(c))\n",
    "        self.vocab,self.otoi = uniqueify(list(vals), sort=True, bidir=True, start='#bg')\n",
    "\n",
    "    def encodes(self, o): return (o[0],tensor([self.otoi[o_] for o_ in o[1] if o_ in self.otoi]))\n",
    "    def decodes(self, i): return (i[0],[self.vocab[i_] for i_ in i[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _lbl1(x): return bboxes\n",
    "tcat = BBoxCategorize(subset_idx=[0])\n",
    "tds = TfmdDS([fn], [[Imagify(), ImageToByteTensor()], [_lbl1,BBoxify(), tcat]], tuple_tfms=BBoxScaler())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = tds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-1.0000, -1.0000, -0.5000, -0.5000],\n",
       "         [ 0.0000, -0.2857,  0.9286,  0.9286]]), (#2) [2,1])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = tds[0]\n",
    "#Scaling and flipping properly done\n",
    "test_close(y[0], tensor([[-1, -1, -0.5, -0.5],[0, -1+10/14, -1+27/14, -1+27/14]]))\n",
    "test_eq(y[1], [2,1])\n",
    "a,b = tds.decode((x,y))\n",
    "test_close(b[0], tensor(bboxes[0]).float())\n",
    "test_eq(b[1], bboxes[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fd66c2f7e48>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "tds.show_at(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tds = TfmdDS([fn], [[Imagify()], [_lbl1,BBoxify(), tcat]], tuple_tfms=[BBoxScaler(), ImageToByteTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = tds[0]\n",
    "#Scaling and flipping properly done\n",
    "test_close(y[0], tensor([[-1, -1, -0.5, -0.5],[0, -1+10/14, -1+27/14, -1+27/14]]))\n",
    "test_eq(y[1], [2,1])\n",
    "a,b = tds.decode((x,y))\n",
    "test_close(b[0], tensor(bboxes[0]).float())\n",
    "test_eq(b[1], bboxes[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fd66cb2f400>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "tds.show_at(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_test.ipynb.\n",
      "Converted 01_core.ipynb.\n",
      "Converted 02_data_pipeline.ipynb.\n",
      "Converted 03_data_external.ipynb.\n",
      "Converted 04_data_core.ipynb.\n",
      "Converted 05_data_source.ipynb.\n",
      "Converted 06_vision_core.ipynb.\n",
      "Converted 07_pets_tutorial-meta.ipynb.\n",
      "Converted 07_pets_tutorial.ipynb.\n",
      "Converted 08_vision_augment.ipynb.\n",
      "Converted 10_layers.ipynb.\n",
      "Converted 11_optimizer.ipynb.\n",
      "Converted 12_learner.ipynb.\n",
      "Converted 13_callback_schedule.ipynb.\n",
      "Converted 14_callback_hook.ipynb.\n",
      "Converted 15_callback_progress.ipynb.\n",
      "Converted 16_callback_tracker.ipynb.\n",
      "Converted 17_callback_fp16.ipynb.\n",
      "Converted 90_notebook_core.ipynb.\n",
      "Converted 91_notebook_export.ipynb.\n",
      "Converted 92_notebook_showdoc.ipynb.\n",
      "Converted 93_notebook_export2html.ipynb.\n",
      "Converted 94_index.ipynb.\n",
      "Converted 95_synth_learner.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from local.notebook.export import notebook2script\n",
    "notebook2script(all_fs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
